{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97d678e6-b41a-4117-80d3-6db714d2aede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score ,cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from scipy import signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e36da1f-75af-4655-a884-b34fedbeade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set random seeds for reproducibility\n",
    "# np.random.seed(42)\n",
    "# torch.manual_seed(42)\n",
    "\n",
    "# Define constants\n",
    "N_CHANNELS_PSG = 6\n",
    "N_CHANNELS_HEADBAND = 2\n",
    "EPOCH_LENGTH_SEC = 30  \n",
    "SAMPLE_RATE = 256  \n",
    "FFT_WINDOW_SIZE = 4  # seconds\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "# Sleep stage labels (standard)\n",
    "SLEEP_STAGES = {\n",
    "    0: 'Wake',\n",
    "    1: 'N1',\n",
    "    2: 'N2',\n",
    "    3: 'N3',\n",
    "    4: 'REM'\n",
    "}\n",
    "SLEEP_STAGES_reverse = {\n",
    "    0:'W',    # Wake\n",
    "    1:'N1',   # Non-REM stage 1\n",
    "    2: 'N2',   # Non-REM stage 2\n",
    "    3: 'N3',   # Non-REM stage 3\n",
    "    4: 'R'     # REM sleep\n",
    "}\n",
    "def load_edf_files(psg_path, headband_path):\n",
    "    \"\"\"Load PSG and headband EDF files\"\"\"\n",
    "    print(\"Loading EDF files...\")\n",
    "    \n",
    "    # Load PSG data\n",
    "    psg_raw = mne.io.read_raw_edf(psg_path, preload=True)\n",
    "    \n",
    "    # Load headband data\n",
    "    headband_raw = mne.io.read_raw_edf(headband_path, preload=True)\n",
    "    \n",
    "    print(f\"PSG channels: {psg_raw.ch_names}\")\n",
    "    print(f\"Headband channels: {headband_raw.ch_names}\")\n",
    "    \n",
    "    return psg_raw, headband_raw\n",
    "    \n",
    "def load_hypnogram(hypno_path):\n",
    "    \"\"\"Load sleep stages from a hypnogram file\"\"\"\n",
    "    # This function would need to be adapted based on your hypnogram format\n",
    "    # For this example, we'll assume a simple CSV with epoch number and stage\n",
    "    # .map(SLEEP_STAGES_reverse).fillna('W')\n",
    "    hypno_df = pd.read_csv(hypno_path, sep='\\t')\n",
    "    sleep_stages = hypno_df['majority'].apply(lambda s: s if s in [0, 1, 2, 3, 4] else 0).values\n",
    "    \n",
    "    return sleep_stages\n",
    "    \n",
    "def synchronize_recordings(psg_raw, headband_raw):\n",
    "    \"\"\"Synchronize PSG and headband recordings based on timestamps\"\"\"\n",
    "    # Extract start times\n",
    "    psg_start = psg_raw.info['meas_date']\n",
    "    headband_start = headband_raw.info['meas_date']\n",
    "    \n",
    "    print(f\"PSG start time: {psg_start}\")\n",
    "    print(f\"Headband start time: {headband_start}\")\n",
    "    \n",
    "    # Calculate offset\n",
    "    if psg_start and headband_start:\n",
    "        time_diff = (headband_start - psg_start).total_seconds()\n",
    "        print(f\"Time difference: {time_diff} seconds\")\n",
    "        \n",
    "        # Determine which recording started first and crop accordingly\n",
    "        if time_diff > 0:\n",
    "            # Headband started later, crop PSG\n",
    "            psg_raw.crop(tmin=time_diff)\n",
    "        else:\n",
    "            # PSG started later, crop headband\n",
    "            headband_raw.crop(tmin=-time_diff)\n",
    "    \n",
    "    # Ensure both recordings have the same duration\n",
    "    duration = min(psg_raw.times[-1], headband_raw.times[-1])\n",
    "    psg_raw.crop(tmax=duration)\n",
    "    headband_raw.crop(tmax=duration)\n",
    "    \n",
    "    print(f\"Synchronized duration: {duration} seconds\")\n",
    "    \n",
    "    return psg_raw, headband_raw\n",
    "\n",
    "def extract_features(raw_data, channel_names, window_size=FFT_WINDOW_SIZE, sample_rate=SAMPLE_RATE):\n",
    "    \"\"\"Extract frequency domain features from EEG signals\"\"\"\n",
    "    # Select only the channels we want\n",
    "    data = raw_data.get_data(picks=channel_names)\n",
    "    \n",
    "    # Calculate number of epochs\n",
    "    n_epochs = int(data.shape[1] / (EPOCH_LENGTH_SEC * sample_rate))\n",
    "    \n",
    "    # Initialize feature arrays\n",
    "    n_channels = len(channel_names)\n",
    "    \n",
    "    # Define frequency bands\n",
    "    bands = {\n",
    "        'delta': (0.5, 4),\n",
    "        'theta': (4, 8),\n",
    "        'alpha': (8, 13),\n",
    "        'beta': (13, 30),\n",
    "        'gamma': (30, 45)\n",
    "    }\n",
    "    \n",
    "    # Initialize feature matrix\n",
    "    n_bands = len(bands)\n",
    "    features = np.zeros((n_epochs, n_channels * n_bands * 2))  # 2 features per band (power, rel_power)\n",
    "    \n",
    "    # Process each epoch\n",
    "    for epoch_idx in range(n_epochs):\n",
    "        start_sample = epoch_idx * EPOCH_LENGTH_SEC * sample_rate\n",
    "        end_sample = (epoch_idx + 1) * EPOCH_LENGTH_SEC * sample_rate\n",
    "        \n",
    "        # Extract epoch data\n",
    "        epoch_data = data[:, start_sample:end_sample]\n",
    "        \n",
    "        # Calculate features for each channel\n",
    "        for ch_idx in range(n_channels):\n",
    "            channel_data = epoch_data[ch_idx, :]\n",
    "            \n",
    "            # Compute power spectral density\n",
    "            freqs, psd = signal.welch(channel_data, fs=sample_rate, nperseg=window_size*sample_rate)\n",
    "            \n",
    "            # Calculate band powers\n",
    "            feature_idx = ch_idx * n_bands * 2\n",
    "            total_power = np.sum(psd)\n",
    "            \n",
    "            for band_idx, (band_name, (low_freq, high_freq)) in enumerate(bands.items()):\n",
    "                # Find indices corresponding to the frequency band\n",
    "                idx_band = np.logical_and(freqs >= low_freq, freqs <= high_freq)\n",
    "                \n",
    "                # Calculate absolute and relative band power\n",
    "                band_power = np.sum(psd[idx_band])\n",
    "                rel_power = band_power / total_power if total_power > 0 else 0\n",
    "                \n",
    "                # Store features\n",
    "                features[epoch_idx, feature_idx + band_idx*2] = band_power\n",
    "                features[epoch_idx, feature_idx + band_idx*2 + 1] = rel_power\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "077863cb-9df8-4604-b291-c1d9f35e944a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SleepDataset(Dataset):\n",
    "    \"\"\"PyTorch dataset for sleep staging\"\"\"\n",
    "    def __init__(self, X, y):\n",
    "        # Convert X and y to numpy arrays with proper types first\n",
    "        if isinstance(X, np.ndarray) and X.dtype == object:\n",
    "            X = np.stack(X).astype(np.float32)\n",
    "        if isinstance(y, np.ndarray) and y.dtype == object:\n",
    "            y = np.array(y, dtype=np.int64)\n",
    "            \n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deb4cc80-d48b-4450-bde2-42edca5e1753",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    \"\"\"Simple transformer model for sleep stage classification\"\"\"\n",
    "    def __init__(self, input_dim, num_classes, d_model=64, nhead=4, num_layers=2, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        # Reshape input to sequence for transformer\n",
    "        # For spectral features, we'll treat each channel-band combination as a token\n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # Project input to d_model dimensions\n",
    "        self.input_projection = nn.Linear(input_dim, d_model)\n",
    "        \n",
    "        # Create positional encoding (fixed)\n",
    "        self.pos_encoder = nn.Sequential(\n",
    "            nn.Linear(1, d_model),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "        # Transformer encoder\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, \n",
    "                                                  dim_feedforward=d_model*4,\n",
    "                                                  dropout=dropout, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model // 2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Reshape input to sequence form\n",
    "        # Here we're treating the whole feature vector as a single token\n",
    "        # For more complex models, you could reshape to have multiple tokens\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Project input\n",
    "        x = self.input_projection(x).unsqueeze(1)  # [batch, 1, d_model]\n",
    "        \n",
    "        # Add positional encoding\n",
    "        positions = torch.zeros(1, 1, 1).to(x.device)\n",
    "        pos_encoding = self.pos_encoder(positions)\n",
    "        x = x + pos_encoding\n",
    "        \n",
    "        # Apply transformer\n",
    "        x = self.transformer_encoder(x)\n",
    "        \n",
    "        # Take the output corresponding to the first position\n",
    "        x = x[:, 0, :]\n",
    "        \n",
    "        # Classify\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
    "    \"\"\"Train the model\"\"\"\n",
    "    model.to(device)\n",
    "    best_val_acc = 0.0\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "        \n",
    "        train_loss = train_loss / train_total\n",
    "        train_acc = train_correct / train_total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\"):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Statistics\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "        \n",
    "        val_loss = val_loss / val_total\n",
    "        val_acc = val_correct / val_total\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}: \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model = model.state_dict().copy()\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(best_model)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    \"\"\"Evaluate the model on test data\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    report = classification_report(all_labels, all_preds, labels=list(SLEEP_STAGES.keys()), target_names=list(SLEEP_STAGES.values()), output_dict=True)\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    print(\"Cohen’s Kappa:\", cohen_kappa_score(all_labels, all_preds))\n",
    "    return acc, report, cm, all_preds, all_labels\n",
    "\n",
    "def visualize_results(cm, report, sleep_stages):\n",
    "    \"\"\"Visualize classification results\"\"\"\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=list(sleep_stages.values()),\n",
    "                yticklabels=list(sleep_stages.values()))\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot performance metrics\n",
    "    metrics = ['precision', 'recall', 'f1-score']\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        values = [report[stage][metric] for stage in sleep_stages.values()]\n",
    "        sns.barplot(x=list(sleep_stages.values()), y=values)\n",
    "        plt.title(f'{metric.capitalize()}')\n",
    "        plt.ylim(0, 1)\n",
    "        plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('performance_metrics.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b2eb7de-f60a-406c-b279-1d77de300c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EDF files...\n",
      "Extracting EDF parameters from C:\\Users\\naikh\\SleepResearchCode_experient\\Dataset_clean_for_jupyter\\sub-94\\eeg\\sub-94_task-Sleep_acq-psg_eeg_6-channels.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 7720703  =      0.000 ... 30158.996 secs...\n",
      "Extracting EDF parameters from C:\\Users\\naikh\\SleepResearchCode_experient\\Dataset_clean_for_jupyter\\sub-94\\eeg\\sub-94_task-Sleep_acq-headband_eeg_2-channels.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 7720703  =      0.000 ... 30158.996 secs...\n",
      "PSG channels: ['PSG_F3', 'PSG_F4', 'PSG_C3', 'PSG_C4', 'PSG_O1', 'PSG_O2']\n",
      "Headband channels: ['HB_1', 'HB_2']\n",
      "Extracting PSG features...\n",
      "Extracting headband features...\n",
      "[0 0 0 ... 2 2 0]\n",
      "Loaded 1005 sleep stage labels\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Main function to compare PSG and headband recordings and evaluate sleep stage prediction\"\"\"\n",
    "# File paths \n",
    "sub_no = 94\n",
    "psg_path = f\"Dataset_clean_for_jupyter/sub-{sub_no}/eeg/sub-{sub_no}_task-Sleep_acq-psg_eeg_6-channels.edf\"\n",
    "headband_path = f\"Dataset_clean_for_jupyter/sub-{sub_no}/eeg/sub-{sub_no}_task-Sleep_acq-headband_eeg_2-channels.edf\" \n",
    "hypnogram_path = f\"Dataset_clean_for_jupyter/sub-{sub_no}/eeg/sub-{sub_no}_task-Sleep_acq-psg_events.tsv\"\n",
    "\n",
    "# 1. Load EDF files\n",
    "psg_raw, headband_raw = load_edf_files(psg_path, headband_path)\n",
    "\n",
    "# 2. Synchronize recordings\n",
    "# psg_raw, headband_raw = synchronize_recordings(psg_raw, headband_raw)\n",
    "\n",
    "# 3. Extract features\n",
    "psg_channels = ['PSG_F3', 'PSG_F4', 'PSG_C3', 'PSG_C4', 'PSG_O1', 'PSG_O2']\n",
    "headband_channels = ['HB_1', 'HB_2']\n",
    "\n",
    "print(\"Extracting PSG features...\")\n",
    "psg_features = extract_features(psg_raw, psg_channels)\n",
    "\n",
    "print(\"Extracting headband features...\")\n",
    "headband_features = extract_features(headband_raw, headband_channels)\n",
    "\n",
    "# 4. Load sleep stages (ground truth)\n",
    "try:\n",
    "    sleep_stages = load_hypnogram(hypnogram_path)\n",
    "    print((sleep_stages))\n",
    "    \n",
    "    print(f\"Loaded {len(sleep_stages)} sleep stage labels\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading hypnogram: {e}\")\n",
    "    print(\"Generating synthetic labels for demonstration purposes\")\n",
    "    # Create synthetic labels for demonstration\n",
    "    n_epochs = psg_features.shape[0]\n",
    "    sleep_stages = np.random.randint(0, 5, size=n_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5ad40c4-4418-4e6a-85d0-549c6c94a33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 703 samples\n",
      "Validation set: 151 samples\n",
      "Test set: 151 samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. Split data into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    headband_features, sleep_stages, test_size=0.3, random_state=42, stratify=sleep_stages\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# 6. Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a8cd63a-afc6-4b68-8294-8a048a244cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7. Create data loaders\n",
    "train_dataset = SleepDataset(X_train, y_train)\n",
    "val_dataset = SleepDataset(X_val, y_val)\n",
    "test_dataset = SleepDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ed6b8e6-ab25-4fed-8004-f186ed42874a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created with 103685 parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 64.71it/s]\n",
      "Epoch 1/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 230.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: Train Loss: 1.5185, Train Acc: 0.3499, Val Loss: 1.4231, Val Acc: 0.6093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 72.37it/s]\n",
      "Epoch 2/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 249.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: Train Loss: 1.3194, Train Acc: 0.6686, Val Loss: 1.2417, Val Acc: 0.6623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 72.85it/s]\n",
      "Epoch 3/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 272.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: Train Loss: 1.1686, Train Acc: 0.7041, Val Loss: 1.0991, Val Acc: 0.6556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 73.83it/s]\n",
      "Epoch 4/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 250.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: Train Loss: 1.0436, Train Acc: 0.6956, Val Loss: 0.9990, Val Acc: 0.6623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 80.89it/s]\n",
      "Epoch 5/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 272.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: Train Loss: 0.9557, Train Acc: 0.6970, Val Loss: 0.9300, Val Acc: 0.6623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 76.39it/s]\n",
      "Epoch 6/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 272.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: Train Loss: 0.8930, Train Acc: 0.6970, Val Loss: 0.8782, Val Acc: 0.6623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 80.23it/s]\n",
      "Epoch 7/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 272.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: Train Loss: 0.8534, Train Acc: 0.7183, Val Loss: 0.8353, Val Acc: 0.6821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 82.09it/s]\n",
      "Epoch 8/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 332.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: Train Loss: 0.8037, Train Acc: 0.7368, Val Loss: 0.7963, Val Acc: 0.7152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 80.29it/s]\n",
      "Epoch 9/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 300.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: Train Loss: 0.7689, Train Acc: 0.7568, Val Loss: 0.7609, Val Acc: 0.7285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 82.70it/s]\n",
      "Epoch 10/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 299.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: Train Loss: 0.7275, Train Acc: 0.7667, Val Loss: 0.7288, Val Acc: 0.7483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 81.48it/s]\n",
      "Epoch 11/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 272.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: Train Loss: 0.6945, Train Acc: 0.7752, Val Loss: 0.7006, Val Acc: 0.7550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 90.91it/s]\n",
      "Epoch 12/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 272.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: Train Loss: 0.6770, Train Acc: 0.7767, Val Loss: 0.6752, Val Acc: 0.7616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 76.94it/s]\n",
      "Epoch 13/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 272.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: Train Loss: 0.6456, Train Acc: 0.7866, Val Loss: 0.6520, Val Acc: 0.7550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 68.74it/s]\n",
      "Epoch 14/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 250.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: Train Loss: 0.6175, Train Acc: 0.7966, Val Loss: 0.6328, Val Acc: 0.7682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 69.62it/s]\n",
      "Epoch 15/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 230.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: Train Loss: 0.5967, Train Acc: 0.7966, Val Loss: 0.6145, Val Acc: 0.7682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 71.43it/s]\n",
      "Epoch 16/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 230.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: Train Loss: 0.5751, Train Acc: 0.7966, Val Loss: 0.5972, Val Acc: 0.7815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 67.90it/s]\n",
      "Epoch 17/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 272.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: Train Loss: 0.5585, Train Acc: 0.8193, Val Loss: 0.5816, Val Acc: 0.7881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 67.91it/s]\n",
      "Epoch 18/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 142.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: Train Loss: 0.5430, Train Acc: 0.8222, Val Loss: 0.5632, Val Acc: 0.7881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 63.58it/s]\n",
      "Epoch 19/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 230.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: Train Loss: 0.5271, Train Acc: 0.8250, Val Loss: 0.5467, Val Acc: 0.7881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 87.31it/s]\n",
      "Epoch 20/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 230.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: Train Loss: 0.5042, Train Acc: 0.8265, Val Loss: 0.5296, Val Acc: 0.7881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 70.31it/s]\n",
      "Epoch 21/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 166.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: Train Loss: 0.4863, Train Acc: 0.8350, Val Loss: 0.5216, Val Acc: 0.7947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 62.50it/s]\n",
      "Epoch 22/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 176.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50: Train Loss: 0.4764, Train Acc: 0.8336, Val Loss: 0.5034, Val Acc: 0.7881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 62.50it/s]\n",
      "Epoch 23/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 230.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50: Train Loss: 0.4700, Train Acc: 0.8236, Val Loss: 0.4917, Val Acc: 0.8278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 77.16it/s]\n",
      "Epoch 24/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 200.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50: Train Loss: 0.4550, Train Acc: 0.8378, Val Loss: 0.4801, Val Acc: 0.8477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 68.75it/s]\n",
      "Epoch 25/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 374.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50: Train Loss: 0.4485, Train Acc: 0.8464, Val Loss: 0.4671, Val Acc: 0.8477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 87.31it/s]\n",
      "Epoch 26/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 300.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50: Train Loss: 0.4428, Train Acc: 0.8464, Val Loss: 0.4519, Val Acc: 0.8477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 84.62it/s]\n",
      "Epoch 27/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 374.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50: Train Loss: 0.4222, Train Acc: 0.8620, Val Loss: 0.4555, Val Acc: 0.8477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 88.71it/s]\n",
      "Epoch 28/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 333.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50: Train Loss: 0.4156, Train Acc: 0.8435, Val Loss: 0.4409, Val Acc: 0.8477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 87.28it/s]\n",
      "Epoch 29/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 374.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50: Train Loss: 0.4065, Train Acc: 0.8478, Val Loss: 0.4335, Val Acc: 0.8477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 82.71it/s]\n",
      "Epoch 30/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 374.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50: Train Loss: 0.4047, Train Acc: 0.8620, Val Loss: 0.4301, Val Acc: 0.8411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 94.83it/s]\n",
      "Epoch 31/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 374.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50: Train Loss: 0.3834, Train Acc: 0.8649, Val Loss: 0.4211, Val Acc: 0.8477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 93.50it/s]\n",
      "Epoch 32/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 374.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50: Train Loss: 0.3869, Train Acc: 0.8706, Val Loss: 0.4262, Val Acc: 0.8411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 92.44it/s]\n",
      "Epoch 33/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 374.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50: Train Loss: 0.3911, Train Acc: 0.8634, Val Loss: 0.4160, Val Acc: 0.8477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 87.30it/s]\n",
      "Epoch 34/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 375.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50: Train Loss: 0.3862, Train Acc: 0.8606, Val Loss: 0.4141, Val Acc: 0.8411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 86.62it/s]\n",
      "Epoch 35/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 375.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50: Train Loss: 0.3733, Train Acc: 0.8706, Val Loss: 0.4022, Val Acc: 0.8411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 93.22it/s]\n",
      "Epoch 36/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 428.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50: Train Loss: 0.3769, Train Acc: 0.8620, Val Loss: 0.3990, Val Acc: 0.8477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 97.35it/s]\n",
      "Epoch 37/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 374.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50: Train Loss: 0.3735, Train Acc: 0.8634, Val Loss: 0.3977, Val Acc: 0.8543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 94.02it/s]\n",
      "Epoch 38/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 375.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50: Train Loss: 0.3555, Train Acc: 0.8805, Val Loss: 0.3942, Val Acc: 0.8543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 92.44it/s]\n",
      "Epoch 39/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 333.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50: Train Loss: 0.3745, Train Acc: 0.8720, Val Loss: 0.3906, Val Acc: 0.8609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 96.49it/s]\n",
      "Epoch 40/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 374.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50: Train Loss: 0.3683, Train Acc: 0.8663, Val Loss: 0.4013, Val Acc: 0.8543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 92.89it/s]\n",
      "Epoch 41/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 300.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50: Train Loss: 0.3612, Train Acc: 0.8748, Val Loss: 0.3842, Val Acc: 0.8609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 94.83it/s]\n",
      "Epoch 42/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 333.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50: Train Loss: 0.3531, Train Acc: 0.8777, Val Loss: 0.3816, Val Acc: 0.8609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 94.02it/s]\n",
      "Epoch 43/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 375.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50: Train Loss: 0.3533, Train Acc: 0.8734, Val Loss: 0.3815, Val Acc: 0.8543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 98.46it/s]\n",
      "Epoch 44/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 300.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50: Train Loss: 0.3561, Train Acc: 0.8762, Val Loss: 0.3807, Val Acc: 0.8675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 88.72it/s]\n",
      "Epoch 45/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 374.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50: Train Loss: 0.3546, Train Acc: 0.8777, Val Loss: 0.3749, Val Acc: 0.8609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 86.62it/s]\n",
      "Epoch 46/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 374.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50: Train Loss: 0.3388, Train Acc: 0.8777, Val Loss: 0.3812, Val Acc: 0.8543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 93.22it/s]\n",
      "Epoch 47/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 375.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50: Train Loss: 0.3453, Train Acc: 0.8720, Val Loss: 0.3727, Val Acc: 0.8609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 91.02it/s]\n",
      "Epoch 48/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 375.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50: Train Loss: 0.3410, Train Acc: 0.8777, Val Loss: 0.3729, Val Acc: 0.8609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 86.61it/s]\n",
      "Epoch 49/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 374.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50: Train Loss: 0.3499, Train Acc: 0.8748, Val Loss: 0.3675, Val Acc: 0.8675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 [Train]: 100%|██████████| 11/11 [00:00<00:00, 49.77it/s]\n",
      "Epoch 50/50 [Val]: 100%|██████████| 3/3 [00:00<00:00, 265.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50: Train Loss: 0.3395, Train Acc: 0.8791, Val Loss: 0.3695, Val Acc: 0.8675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3/3 [00:00<00:00, 375.31it/s]\n",
      "C:\\Users\\naikh\\anaconda3\\envs\\TensorFlowEnv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\naikh\\anaconda3\\envs\\TensorFlowEnv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\naikh\\anaconda3\\envs\\TensorFlowEnv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\naikh\\anaconda3\\envs\\TensorFlowEnv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\naikh\\anaconda3\\envs\\TensorFlowEnv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\naikh\\anaconda3\\envs\\TensorFlowEnv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\naikh\\anaconda3\\envs\\TensorFlowEnv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\naikh\\anaconda3\\envs\\TensorFlowEnv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\naikh\\anaconda3\\envs\\TensorFlowEnv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen’s Kappa: 0.6852974611595302\n",
      "\n",
      "Test Accuracy: 0.8543\n",
      "\n",
      "Classification Report:\n",
      "Wake: Precision: 0.5625, Recall: 0.9000, F1: 0.6923\n",
      "N1: Precision: 1.0000, Recall: 0.5000, F1: 0.6667\n",
      "N2: Precision: 0.9065, Recall: 0.9151, F1: 0.9108\n",
      "N3: Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "REM: Precision: 0.8000, Recall: 0.6897, F1: 0.7407\n",
      "\n",
      "Comparing with PSG-based model:\n",
      "\n",
      "Headband Accuracy Assessment:\n",
      "Overall accuracy: 0.8543\n",
      "Weighted F1 score: 0.8540\n",
      "\n",
      "Sleep Architecture Comparison:\n",
      "Wake: True: 0.0662, Predicted: 0.1060, Difference: 0.0397\n",
      "N1: True: 0.0397, Predicted: 0.0199, Difference: 0.0199\n",
      "N2: True: 0.7020, Predicted: 0.7086, Difference: 0.0066\n",
      "N3: True: 0.0000, Predicted: 0.0000, Difference: 0.0000\n",
      "REM: True: 0.1921, Predicted: 0.1656, Difference: 0.0265\n",
      "\n",
      "Overall assessment: The headband shows Excellent accuracy for sleep stage prediction.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 8. Initialize model\n",
    "input_dim = X_train.shape[1]\n",
    "num_classes = len(SLEEP_STAGES)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = TransformerModel(input_dim, num_classes)\n",
    "print(f\"Model created with {sum(p.numel() for p in model.parameters())} parameters\")\n",
    "\n",
    "# 9. Train model\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "model = train_model(model, train_loader, val_loader, criterion, optimizer, NUM_EPOCHS, device)\n",
    "\n",
    "# 10. Evaluate model\n",
    "accuracy, report, cm, predictions, true_labels = evaluate_model(model, test_loader, device)\n",
    "\n",
    "print(f\"\\nTest Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "for stage, metrics in report.items():\n",
    "    if stage in SLEEP_STAGES.values():\n",
    "        print(f\"{stage}: Precision: {metrics['precision']:.4f}, Recall: {metrics['recall']:.4f}, F1: {metrics['f1-score']:.4f}\")\n",
    "\n",
    "# 11. Visualize results\n",
    "visualize_results(cm, report, SLEEP_STAGES)\n",
    "\n",
    "# 12. Compare with PSG-based model (optional)\n",
    "print(\"\\nComparing with PSG-based model:\")\n",
    "# Here you could implement a similar pipeline for PSG features\n",
    "# and compare the performance\n",
    "\n",
    "# 13. Generate report on headband accuracy\n",
    "print(\"\\nHeadband Accuracy Assessment:\")\n",
    "print(f\"Overall accuracy: {accuracy:.4f}\")\n",
    "\n",
    "weighted_f1 = report['weighted avg']['f1-score']\n",
    "print(f\"Weighted F1 score: {weighted_f1:.4f}\")\n",
    "\n",
    "# Sleep architecture analysis\n",
    "true_distribution = np.bincount(true_labels, minlength=len(SLEEP_STAGES)) / len(true_labels)\n",
    "pred_distribution = np.bincount(predictions, minlength=len(SLEEP_STAGES)) / len(predictions)\n",
    "\n",
    "print(\"\\nSleep Architecture Comparison:\")\n",
    "for i, stage in SLEEP_STAGES.items():\n",
    "    print(f\"{stage}: True: {true_distribution[i]:.4f}, Predicted: {pred_distribution[i]:.4f}, \" \n",
    "          f\"Difference: {abs(true_distribution[i] - pred_distribution[i]):.4f}\")\n",
    "\n",
    "# Final assessment\n",
    "if accuracy > 0.8:\n",
    "    assessment = \"Excellent\"\n",
    "elif accuracy > 0.7:\n",
    "    assessment = \"Good\"\n",
    "elif accuracy > 0.6:\n",
    "    assessment = \"Moderate\"\n",
    "else:\n",
    "    assessment = \"Poor\"\n",
    "\n",
    "print(f\"\\nOverall assessment: The headband shows {assessment} accuracy for sleep stage prediction.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b50ccafb-12db-443d-9861-428cf41a2915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.8543\n",
      "\n",
      "Classification Report:\n",
      "Wake: Precision: 0.5625, Recall: 0.9000, F1: 0.6923\n",
      "N1: Precision: 1.0000, Recall: 0.5000, F1: 0.6667\n",
      "N2: Precision: 0.9065, Recall: 0.9151, F1: 0.9108\n",
      "N3: Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "REM: Precision: 0.8000, Recall: 0.6897, F1: 0.7407\n",
      "\n",
      "Comparing with PSG-based model:\n",
      "\n",
      "Headband Accuracy Assessment:\n",
      "Overall accuracy: 0.8543\n",
      "Weighted F1 score: 0.8540\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTest Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "for stage, metrics in report.items():\n",
    "    if stage in SLEEP_STAGES.values():\n",
    "        print(f\"{stage}: Precision: {metrics['precision']:.4f}, \"\n",
    "              f\"Recall: {metrics['recall']:.4f}, \"\n",
    "              f\"F1: {metrics['f1-score']:.4f}\")\n",
    "\n",
    "# 11. Visualize results\n",
    "visualize_results(cm, report, SLEEP_STAGES)\n",
    "\n",
    "# 12. Compare with PSG-based model (optional)\n",
    "print(\"\\nComparing with PSG-based model:\")\n",
    "# Here you could implement a similar pipeline for PSG features\n",
    "# and compare the performance\n",
    "\n",
    "# 13. Generate report on headband accuracy\n",
    "print(\"\\nHeadband Accuracy Assessment:\")\n",
    "print(f\"Overall accuracy: {accuracy:.4f}\")\n",
    "weighted_f1 = report['weighted avg']['f1-score']\n",
    "print(f\"Weighted F1 score: {weighted_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99a5c7a2-6acf-4e16-81c2-8f758fbe3064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comprehensive Sleep Stage Evaluation:\n",
      "+---------------+----------+---------------+--------------+-------------+----------+------------+\n",
      "| Sleep Stage   | True %   | Predicted %   | Difference   |   Precision |   Recall |   F1-Score |\n",
      "+===============+==========+===============+==============+=============+==========+============+\n",
      "| Wake          | 6.62%    | 10.60%        | 3.97%        |      0.5625 |   0.9    |     0.6923 |\n",
      "+---------------+----------+---------------+--------------+-------------+----------+------------+\n",
      "| N1            | 3.97%    | 1.99%         | 1.99%        |      1      |   0.5    |     0.6667 |\n",
      "+---------------+----------+---------------+--------------+-------------+----------+------------+\n",
      "| N2            | 70.20%   | 70.86%        | 0.66%        |      0.9065 |   0.9151 |     0.9108 |\n",
      "+---------------+----------+---------------+--------------+-------------+----------+------------+\n",
      "| N3            | 0.00%    | 0.00%         | 0.00%        |      0      |   0      |     0      |\n",
      "+---------------+----------+---------------+--------------+-------------+----------+------------+\n",
      "| REM           | 19.21%   | 16.56%        | 2.65%        |      0.8    |   0.6897 |     0.7407 |\n",
      "+---------------+----------+---------------+--------------+-------------+----------+------------+\n",
      "| Overall       | 100.00%  | 100.00%       | 4.64%        |      0.867  |   0.8543 |     0.854  |\n",
      "+---------------+----------+---------------+--------------+-------------+----------+------------+\n"
     ]
    }
   ],
   "source": [
    "# Generate comprehensive sleep stage evaluation table\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "# Sleep architecture analysis\n",
    "true_distribution = np.bincount(true_labels, minlength=len(SLEEP_STAGES)) / len(true_labels)\n",
    "pred_distribution = np.bincount(predictions, minlength=len(SLEEP_STAGES)) / len(predictions)\n",
    "\n",
    "\n",
    "# Prepare data for the table\n",
    "table_data = []\n",
    "headers = [\"Sleep Stage\", \"True %\", \"Predicted %\", \"Difference\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "\n",
    "# Populate the table data\n",
    "for i, stage in SLEEP_STAGES.items():\n",
    "    if stage in report:  # Make sure the stage exists in the report\n",
    "        row = [\n",
    "            stage,\n",
    "            f\"{true_distribution[i]:.2%}\",\n",
    "            f\"{pred_distribution[i]:.2%}\",\n",
    "            f\"{abs(true_distribution[i] - pred_distribution[i]):.2%}\",\n",
    "            f\"{report[stage]['precision']:.4f}\",\n",
    "            f\"{report[stage]['recall']:.4f}\",\n",
    "            f\"{report[stage]['f1-score']:.4f}\"\n",
    "        ]\n",
    "        table_data.append(row)\n",
    "\n",
    "# Add summary row\n",
    "table_data.append([\n",
    "    \"Overall\",\n",
    "    \"100.00%\",\n",
    "    \"100.00%\",\n",
    "    f\"{sum(abs(true_distribution - pred_distribution))/2:.2%}\",  # Total distribution error\n",
    "    f\"{report['weighted avg']['precision']:.4f}\",\n",
    "    f\"{report['weighted avg']['recall']:.4f}\",\n",
    "    f\"{report['weighted avg']['f1-score']:.4f}\"\n",
    "])\n",
    "\n",
    "# Print the table\n",
    "print(\"\\nComprehensive Sleep Stage Evaluation:\")\n",
    "print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "751b9070-d705-4935-bfd4-67a863c58e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall assessment: The headband shows Excellent accuracy for sleep stage prediction.\n",
      "Test Accuracy: 0.8543\n"
     ]
    }
   ],
   "source": [
    "# Print overall assessment\n",
    "# Final assessment\n",
    "if accuracy > 0.8:\n",
    "    assessment = \"Excellent\"\n",
    "elif accuracy > 0.7:\n",
    "    assessment = \"Good\"\n",
    "elif accuracy > 0.6:\n",
    "    assessment = \"Moderate\"\n",
    "else:\n",
    "    assessment = \"Poor\"\n",
    "print(f\"\\nOverall assessment: The headband shows {assessment} accuracy for sleep stage prediction.\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a82ba9-4c5d-4018-b805-83eef47439fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
